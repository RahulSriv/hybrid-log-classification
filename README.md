# Log Classification using a Hybrid Classification Framework [Regex, BERT and LLM]

## Overview

This project implements a **hybrid log classification system** that leverages three complementary techniques to effectively handle log patterns of varying complexity â€” from predictable to complex and sparsely labeled. This approach ensures scalability, adaptability, and high accuracy in real-world log analysis.


## ğŸš€ Classification Approaches

### 1. Regular Expression (Regex)

* Handles simple and predictable patterns.
* Useful for patterns that can be identified using rule-based logic.
* Example:

  * `User User101 logged in.` â” **User Action**

### 2. Sentence Transformer + Logistic Regression

* Manages more complex patterns when sufficient labeled data is available.
* Uses **BERT embeddings** generated by `sentence-transformers`.
* Applies **Logistic Regression** for classification.
* Example:

  * `Payment error: code 503.` â” **Transaction Error**

### 3. LLM (Large Language Models)

* Used when labeled training data is sparse or unavailable.
* Acts as a fallback/complementary mechanism.
* Example:

  * `Unexpected shutdown detected.` â” **Anomaly**

![flowchart.png](resources/flowchart.png)


## ğŸ¤– Tech Stack

| Component    | Technology                         |
| ------------ | ---------------------------------- |
| Embeddings   | BERT (`all-MiniLM-L6-v2`)          |
| ML Model     | Logistic Regression (Scikit-learn) |
| Regex Engine | Python `re` module                 |
| LLM          | DeepSeek R1 or LLaMA               |
| API Layer    | FastAPI                            |

## âš ï¸ Problem Statement

### Issues:

* Delays in detecting critical issues
* Operational inefficiencies
* Missed anomalies due to imperfect logging practices

### Why log level-based monitoring isn't perfect:

* Developers often write inconsistent or incomplete log messages

## ğŸ“Š Solution

A **log classification and monitoring system** that categorizes logs based on functional meaning, not just severity level. This enhances alerting, analytics, and debugging.

```
aggregated logs â” hybrid classification system â” log monitoring/dashboard
```
## âœ¨ Benefits of Hybrid Classification

* Optimized **cost and performance**
* Improved **accuracy**
* **Scalable** across multiple sources and formats

## ğŸ“‚ Repository Structure

```
Logs Classification System/
â”œâ”€â”€ models/
â”‚   â””â”€â”€ log_hybrid_classifier.joblib
â”œâ”€â”€ resources/
â”‚   â”œâ”€â”€ api_response_snapshot.png
â”‚   â”œâ”€â”€ flowchart.png
â”‚   â”œâ”€â”€ input.csv
â”‚   â””â”€â”€ output.csv
â”œâ”€â”€ training/
â”‚   â”œâ”€â”€ dataset/
â”‚   â”‚   â””â”€â”€ synthetic_logs.csv
â”‚   â””â”€â”€ training.ipynb
â”œâ”€â”€ classify.py
â”œâ”€â”€ processor_bert.py
â”œâ”€â”€ processor_llm.py
â”œâ”€â”€ processor_regex.py
â”œâ”€â”€ server.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ğŸš€ Setup Instructions

### 1. Install Dependencies

```bash
pip install -r requirements.txt
```

### 2. Run FastAPI Server

```bash
uvicorn server:app --reload
```

### 3. Access API

* Endpoint: [http://127.0.0.1:8000/classify](http://127.0.0.1:8000/classify)


## âœï¸ Usage Instructions

Upload a CSV file containing logs to the FastAPI endpoint for classification.

### Input CSV Columns: 

* `source`
* `log_message`

```
source,log_message
app,User User123 logged out.
legacy,Backup completed successfully.
```

### Output CSV:

* Adds a new column: `target_label`
* Example:

```
source,log_message,target_label
app,User User123 logged out.,User Action
legacy,Backup completed successfully.,System Notification
```

## ğŸš€ Future Scope

* Add visualization dashboards
* Auto-regex rule generation using NLP pattern mining
* Fine-tuned transformer for domain-specific logs
* Support for real-time log streaming (Kafka integration)


---
